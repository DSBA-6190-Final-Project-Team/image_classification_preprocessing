{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notes\n",
    "## Project Folder Structure\n",
    "The data for this file is too large to store with the github repo. Therefore, the files need to be added manually. The raw image files can be found here:\n",
    "\n",
    "[https://www.kaggle.com/c/state-farm-distracted-driver-detection/data](https://www.kaggle.com/c/state-farm-distracted-driver-detection/data) (Accessed on 3/21/2020)\n",
    "\n",
    "The file structre should be as follows:\n",
    "\n",
    "-Working\n",
    "\n",
    "--imgs\n",
    "  \n",
    "---train\n",
    "\n",
    "---test\n",
    "\n",
    "The train and test folders come directly from the kaggle dataset. Subsequent folders will be generated by this notebook.\n",
    "## Scope\n",
    "This notebook is to prepare the images in the distracted driver dataset locally, for upload to S3.\n",
    "\n",
    "This notebook will create two versions of the data. The first will be a LST mapping file, with the image files in JPEG format. The second will be a recordio format.\n",
    "\n",
    "A Complete dataset and Sample dataset will be created and uploaded."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: checksumdir in c:\\users\\canfi\\anaconda2\\envs\\dsba_6190_team_proj\\lib\\site-packages (1.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install checksumdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z9yTpGbACbX"
   },
   "source": [
    "## Library / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhXJ8brV_4Qb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "\n",
    "import hashlib\n",
    "from checksumdir import dirhash\n",
    "\n",
    "from filecmp import dircmp\n",
    "\n",
    "#Settings\n",
    "seed = 5590"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "406FN849AG3C"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpUao_lNAE88"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/DSBA-6190-Final-Project-Team/DSBA-6190_Final-Project/master/wine_predict/data/driver_imgs_list.csv\"\n",
    "path_file = 'data/driver_imgs_list.csv'\n",
    "\n",
    "df_driver_index = pd.read_csv(path_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr04mwBdAwNY"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1W_1IwhLA7vT",
    "outputId": "6c263b25-d00d-46cc-c0cc-35a5f5e9f47c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "n3glHqjBA3wI",
    "outputId": "d57b86d9-fe7b-4640-f241-3cba70bfab9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R-sfjF4eAyMI",
    "outputId": "2a8fafe6-343c-4cc7-8b1c-5f64856d2518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'classname', 'img'], dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2w7VZnGBz8G"
   },
   "source": [
    "The following lists each unique driver along with the number of different classname and images are associated with each. Note the number of classnames is not unique, so the images an classnames have equal frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "_vqngHEZBEVL",
    "outputId": "f391960d-5245-42b3-ba56-0cde324c5a5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p002</th>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p012</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p014</th>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p015</th>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p016</th>\n",
       "      <td>1078</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p021</th>\n",
       "      <td>1237</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p022</th>\n",
       "      <td>1233</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p024</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p026</th>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p035</th>\n",
       "      <td>848</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p041</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p042</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p045</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p047</th>\n",
       "      <td>835</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p049</th>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p050</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p051</th>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p052</th>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p056</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p061</th>\n",
       "      <td>809</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p064</th>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p066</th>\n",
       "      <td>1034</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p072</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p075</th>\n",
       "      <td>814</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p081</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         classname   img\n",
       "subject                 \n",
       "p002           725   725\n",
       "p012           823   823\n",
       "p014           876   876\n",
       "p015           875   875\n",
       "p016          1078  1078\n",
       "p021          1237  1237\n",
       "p022          1233  1233\n",
       "p024          1226  1226\n",
       "p026          1196  1196\n",
       "p035           848   848\n",
       "p039           651   651\n",
       "p041           605   605\n",
       "p042           591   591\n",
       "p045           724   724\n",
       "p047           835   835\n",
       "p049          1011  1011\n",
       "p050           790   790\n",
       "p051           920   920\n",
       "p052           740   740\n",
       "p056           794   794\n",
       "p061           809   809\n",
       "p064           820   820\n",
       "p066          1034  1034\n",
       "p072           346   346\n",
       "p075           814   814\n",
       "p081           823   823"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_gb = df_driver_index.groupby(['subject'])\n",
    "drivers_gb.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0KTpe42Cqi6"
   },
   "source": [
    "We will set the training/validation split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNDV8uWICp9y"
   },
   "outputs": [],
   "source": [
    "train_val_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6gBnk_kDXtt"
   },
   "source": [
    "To split the data into training and validation sets, we'll need a unique index of drivers. We don't need the frequency counts.\n",
    "\n",
    "We will create a shuffled list of unique drivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5Lps82L_Dn9-",
    "outputId": "f0aff480-dc8e-471a-d45f-ee9fd2f8d09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042', 'p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_unique = drivers_gb.groups.keys()\n",
    "drivers_unique = list(drivers_unique)\n",
    "\n",
    "random.Random(seed).shuffle(drivers_unique)\n",
    "print(drivers_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOClOK2lEZsD"
   },
   "source": [
    "We'll set the list of drivers in the train set and the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzmgBKnHEfmx"
   },
   "outputs": [],
   "source": [
    "num_drivers_val = round(len(drivers_unique)*train_val_split)\n",
    "#print(num_drivers_val)\n",
    "num_drivers_train = len(drivers_unique) - num_drivers_val\n",
    "#print(num_drivers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "keIIvYaDFeGv",
    "outputId": "a0445d0d-d0e2-4780-a6ab-8ae3abce0bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042']\n"
     ]
    }
   ],
   "source": [
    "drivers_val = drivers_unique[:num_drivers_val]\n",
    "print(drivers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aA1httPIFte_",
    "outputId": "e23ed327-f12f-408b-bf00-8cfeb1d49f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_train = drivers_unique[-num_drivers_train:]\n",
    "print(drivers_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNA4cd_cPquX"
   },
   "source": [
    "# Training and Validation Image Lists\n",
    "We'll now create two lists, one list of every image file name associated with the trainging set, another list associated with the validation set. \n",
    "\n",
    "We will use these lists to filter the overall lst mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8a4uhBKP-uQ"
   },
   "outputs": [],
   "source": [
    "df_images_val = df_driver_index[df_driver_index['subject'].isin(drivers_val)]\n",
    "df_images_train = df_driver_index[~df_driver_index['subject'].isin(drivers_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "vHXC2dsXQ2Po",
    "outputId": "d2f863d9-7bdb-493f-d31e-148314e19378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15686, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_train.shape)\n",
    "df_images_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "ex0G4NQCRn0j",
    "outputId": "cc7473cf-2acc-41b2-aa75-507a59349d7c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6738, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_27079.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_50749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_97089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_37741.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject classname            img\n",
       "725    p012        c0  img_10206.jpg\n",
       "726    p012        c0  img_27079.jpg\n",
       "727    p012        c0  img_50749.jpg\n",
       "728    p012        c0  img_97089.jpg\n",
       "729    p012        c0  img_37741.jpg"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_val.shape)\n",
    "df_images_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Images\n",
    "We need to create two folders images, one for training, and one for validation. We will leave the complete folder of images alone, in case we need to go back and extract information from that folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Copy\n",
    "The following function takes the training or validaiton dataframe and iterates through each row. It then copies each file from the overall data to the respective folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_imgs_all(status, df):\n",
    "    prefix_overall = \"imgs\\\\train\"\n",
    "    folder_suffix = \"_subset\"\n",
    "    folder_name = status + folder_suffix\n",
    "    prefix_status = os.path.join(\"imgs\",folder_name)\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        path_src = os.path.join(prefix_overall,\n",
    "                                row['classname'], \n",
    "                                row['img']).replace('\\\\','/')\n",
    "             \n",
    "       \n",
    "        path_dst = os.path.join(\"imgs\",\n",
    "                               folder_name, \n",
    "                               row['classname'],\n",
    "                               row['img']).replace('\\\\','/')\n",
    "        \n",
    "        #print(\"Source File:\\t\\t{}\".format(path_src))\n",
    "        #print(\"Destination File:\\t{}\".format(path_dst))\n",
    "    \n",
    "        \n",
    "        if not os.path.exists(path_dst):\n",
    "            # Verify Directory Exists. Create if Not \n",
    "            os.makedirs(os.path.dirname(path_dst), exist_ok=True)\n",
    "            \n",
    "            shutil.copy(path_src, path_dst)\n",
    "            #print(\"Loop Start\")\n",
    "            #print(\"Source File:\\t\\t{}\".format(path_src))\n",
    "            #print(\"Destination File:\\t{}\".format(path_dst))\n",
    "            #print()\n",
    "        #else:\n",
    "            #print(\"File Exists. No Copy Made.\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a dictionary containing the status and associated dataframes. This will be looped over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_image_df = {\n",
    "    \"train\": df_images_train,\n",
    "    \"validation\" : df_images_val\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_image_df:\n",
    "    copy_imgs_all(key, dict_image_df[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now check there are the correct number of files in each directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_current = \"D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\"\n",
    "prefix_training = \"imgs\\\\train_subset\"\n",
    "prefix_validation = \"imgs\\\\validation_subset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Analyzed:\tD:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\imgs\\train_subset\n",
      "There are 15686 image files in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "dir_train = os.path.join(path_current, prefix_training)\n",
    "print(\"Path Analyzed:\\t{}\".format(dir_train))\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_train)])\n",
    "print(\"There are {} image files in the training dataset.\".format(cpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path Analyzed:\tD:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\imgs\\validation_subset\n",
      "There are 6738 image files in the validation dataset.\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "dir_val = os.path.join(path_current, prefix_validation)\n",
    "print(\"Path Analyzed:\\t{}\".format(dir_val))\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_val)])\n",
    "print(\"There are {} image files in the validation dataset.\".format(cpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "In order to test the image classification algorithm, we are going to create a subsample of the training and validation test sets. We will need to create a list of images for each, and then copy the images into their own directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">c0</th>\n",
       "      <th>6903</th>\n",
       "      <td>p024</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_86347.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4449</th>\n",
       "      <td>p021</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69997.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9311</th>\n",
       "      <td>p035</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_30218.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17010</th>\n",
       "      <td>p056</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_17591.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15491</th>\n",
       "      <td>p051</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_24357.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">c9</th>\n",
       "      <th>4273</th>\n",
       "      <td>p016</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_43974.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13457</th>\n",
       "      <td>p047</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_55331.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2386</th>\n",
       "      <td>p014</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_36650.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13507</th>\n",
       "      <td>p047</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_44150.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18519</th>\n",
       "      <td>p061</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_81214.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1567 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject classname            img\n",
       "classname                                       \n",
       "c0        6903     p024        c0  img_86347.jpg\n",
       "          4449     p021        c0  img_69997.jpg\n",
       "          9311     p035        c0  img_30218.jpg\n",
       "          17010    p056        c0  img_17591.jpg\n",
       "          15491    p051        c0  img_24357.jpg\n",
       "...                 ...       ...            ...\n",
       "c9        4273     p016        c9  img_43974.jpg\n",
       "          13457    p047        c9  img_55331.jpg\n",
       "          2386     p014        c9  img_36650.jpg\n",
       "          13507    p047        c9  img_44150.jpg\n",
       "          18519    p061        c9  img_81214.jpg\n",
       "\n",
       "[1567 rows x 3 columns]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_train_sample = df_images_train.groupby('classname').apply(pd.DataFrame.sample, \n",
    "                                                                    frac = sample_rate, \n",
    "                                                                    random_state = seed)\n",
    "df_images_train_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classname</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">c0</th>\n",
       "      <th>8202</th>\n",
       "      <td>p026</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_34269.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11400</th>\n",
       "      <td>p042</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_59032.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13573</th>\n",
       "      <td>p049</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_11474.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8177</th>\n",
       "      <td>p026</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_26025.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>p022</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_9678.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">c9</th>\n",
       "      <th>11937</th>\n",
       "      <td>p042</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_20372.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12668</th>\n",
       "      <td>p045</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_75520.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14464</th>\n",
       "      <td>p049</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_30754.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1495</th>\n",
       "      <td>p012</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_74547.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14420</th>\n",
       "      <td>p049</td>\n",
       "      <td>c9</td>\n",
       "      <td>img_44355.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>673 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                subject classname            img\n",
       "classname                                       \n",
       "c0        8202     p026        c0  img_34269.jpg\n",
       "          11400    p042        c0  img_59032.jpg\n",
       "          13573    p049        c0  img_11474.jpg\n",
       "          8177     p026        c0  img_26025.jpg\n",
       "          5662     p022        c0   img_9678.jpg\n",
       "...                 ...       ...            ...\n",
       "c9        11937    p042        c9  img_20372.jpg\n",
       "          12668    p045        c9  img_75520.jpg\n",
       "          14464    p049        c9  img_30754.jpg\n",
       "          1495     p012        c9  img_74547.jpg\n",
       "          14420    p049        c9  img_44355.jpg\n",
       "\n",
       "[673 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_val_sample = df_images_val.groupby('classname').apply(pd.DataFrame.sample, \n",
    "                                                                frac = sample_rate, \n",
    "                                                                random_state = seed)\n",
    "df_images_val_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_imgs_sample(status, df):\n",
    "    path_prefix_all = \"imgs\"\n",
    "    path_prefix_sample = \"imgs/sample\"\n",
    "    folder_name = status + \"_subset\"\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        path_src = os.path.join(path_prefix_all,\n",
    "                                folder_name,\n",
    "                                row['classname'], \n",
    "                                row['img']).replace('\\\\','/')\n",
    "                \n",
    "        path_dst = os.path.join(path_prefix_sample,\n",
    "                               folder_name,\n",
    "                               row['classname'],\n",
    "                               row['img']).replace('\\\\','/')\n",
    "        \n",
    "        #print(\"Loop Start\")\n",
    "        #print(\"Source File:\\t\\t{}\".format(path_src))\n",
    "        #print(\"Destination File:\\t{}\".format(path_dst))\n",
    "        #print(\"\")    \n",
    "        \n",
    "        # verify\n",
    "        os.makedirs(os.path.dirname(path_dst), exist_ok=True)\n",
    "        \n",
    "        if not os.path.exists(path_dst):\n",
    "            shutil.copy(path_src, path_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train':                 subject classname            img\n",
       " classname                                       \n",
       " c0        6903     p024        c0  img_86347.jpg\n",
       "           4449     p021        c0  img_69997.jpg\n",
       "           9311     p035        c0  img_30218.jpg\n",
       "           17010    p056        c0  img_17591.jpg\n",
       "           15491    p051        c0  img_24357.jpg\n",
       " ...                 ...       ...            ...\n",
       " c9        4273     p016        c9  img_43974.jpg\n",
       "           13457    p047        c9  img_55331.jpg\n",
       "           2386     p014        c9  img_36650.jpg\n",
       "           13507    p047        c9  img_44150.jpg\n",
       "           18519    p061        c9  img_81214.jpg\n",
       " \n",
       " [1567 rows x 3 columns],\n",
       " 'validation':                 subject classname            img\n",
       " classname                                       \n",
       " c0        8202     p026        c0  img_34269.jpg\n",
       "           11400    p042        c0  img_59032.jpg\n",
       "           13573    p049        c0  img_11474.jpg\n",
       "           8177     p026        c0  img_26025.jpg\n",
       "           5662     p022        c0   img_9678.jpg\n",
       " ...                 ...       ...            ...\n",
       " c9        11937    p042        c9  img_20372.jpg\n",
       "           12668    p045        c9  img_75520.jpg\n",
       "           14464    p049        c9  img_30754.jpg\n",
       "           1495     p012        c9  img_74547.jpg\n",
       "           14420    p049        c9  img_44355.jpg\n",
       " \n",
       " [673 rows x 3 columns]}"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_image_df_sample = {\n",
    "    \"train\": df_images_train_sample,\n",
    "    \"validation\" : df_images_val_sample\n",
    "}\n",
    "\n",
    "dict_image_df_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in dict_image_df_sample:\n",
    "    copy_imgs_sample(key, dict_image_df[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Flow\n",
    "\n",
    "Some of the downstream processing steps are computationally heavy. Therefore, in order to avoid running these code chunks, without manually commenting them out once run. \n",
    "\n",
    "To check if any of the input files have changed, which would then require reprocessing the images, we will use Hash checksum values to document the state of the inputs. We will check against this state to determine if we need to reprocess the data. \n",
    "\n",
    "To do this, we will have to convert the processing steps into callable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2rec Function Calls\n",
    "The following functions use the im2rec.py tool to process the image inputs.\n",
    "\n",
    "[https://mxnet.apache.org/api/faq/recordio](https://mxnet.apache.org/api/faq/recordio) (Accessed on 3/20/2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LST File Generation\n",
    "This function performs the first step, creating LST mapping files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst(status):\n",
    "    lst_file = \"lst_files/\" + status + \"_subset\"\n",
    "    img_loc = \"imgs/\" + status + \"_subset\"\n",
    "    \n",
    "    %run tools/im2rec.py {lst_file} {img_loc} --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recordio Conversion\n",
    "This function converts the images into a binary recordio binary file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_rec(status):\n",
    "    lst_file = \"lst_files/\" + status + \".lst\"\n",
    "    img_loc = \"imgs/\" + status + \"_subset\"\n",
    "    \n",
    "    %run tools/im2rec.py {lst_file} {img_loc}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Hash Checksum\n",
    "The following function generates the Hash of a directory (training or validation images) and writes the Hash in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hash(status):\n",
    "    # Generate File Name, Path and Directory\n",
    "    file_name = \"{}_imgs_hash.csv\".format(status)\n",
    "    file_path = os.path.join(\"hash\", file_name)\n",
    "    file_dir = os.path.join('imgs', status)\n",
    "    \n",
    "    # Generate Hash\n",
    "    dir_hash = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    # Write to CSV\n",
    "    dict_dir_hash = {'hash': [dir_hash]}\n",
    "    df_dir_hash = pd.DataFrame(dict_dir_hash)\n",
    "    df_dir_hash.to_csv(file_path, index=False)\n",
    "    print(\"Hash for {} images successfully written to CSV.\".format(status))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Processing and Writing Hash\n",
    "Whenever we process the input data we need to write a new hash, and vice versa. Therefore, for simplicity in the final code, we will lump these actions together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_and_write(status):\n",
    "        print(\"Generating LST File: {}\".format(status))\n",
    "        \n",
    "        im2rec_lst(status)\n",
    "        \n",
    "        print(\"Starting generating REC fil: {}\".format(status))\n",
    "        \n",
    "        im2rec_rec(status)\n",
    "        \n",
    "        print(\"REC File complete.\")\n",
    "        \n",
    "        write_hash(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow Function\n",
    "The following function will verify the hash of the current files matches the older record. If they match, no action is taken. If they do not match, the input data is processed, and a new hash is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hash(status):\n",
    "    print()\n",
    "    print(\"Status: {}\".format(status))\n",
    "    print()\n",
    "    \n",
    "    # Generate File Name, Path and Directory\n",
    "    file_name = \"{}_imgs_hash.csv\".format(status)\n",
    "    file_path = os.path.join(\"hash\", file_name)\n",
    "    file_dir = os.path.join('imgs', status)\n",
    "    \n",
    "    # Print for Sanity Check\n",
    "    print(\"File Name: {}\".format(file_name))\n",
    "    print(\"File Path: {}\".format(file_path))\n",
    "    print(\"File Directory: {}\".format(file_dir))\n",
    "    print()\n",
    "    \n",
    "    # Generate Current Hash\n",
    "    hash_new = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Hash for {} images do not exist.\".format(status))\n",
    "        print()\n",
    "        im2rec_and_write(status)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        # Read Existing Hash\n",
    "        df_hash_old = pd.read_csv(file_path)\n",
    "        hash_old = df_hash_old.iloc[0]['hash']\n",
    "        \n",
    "        if hash_old == hash_new:\n",
    "            print(\"Hash for {} images are equal.\".format(status))\n",
    "            print(\"New Hash not generated. Processing not required.\")\n",
    "            print()\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            print(\"Hash for {} images are NOT equal.\".format(status))\n",
    "            print()\n",
    "            im2rec_and_write(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Process\n",
    "Runnign the following code chuck will execute the process flow function develpoed above for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for status in status_list:\n",
    "    verify_hash(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Upload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Establish AWS Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile = 'dsba_6190_proj_4'\n",
    "region = 'us-east-1'\n",
    "bucket = 'dsba-6190-final-team-project'\n",
    "prefix = \"channels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = boto3.session.Session(profile_name = profile,\n",
    "                               region_name = region)\n",
    "\n",
    "s3_resource = session.resource('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "train_file = \"lst_files/train.rec\"\n",
    "train_s3_key = os.path.join(prefix, \"train\", \"train.rec\").replace('\\\\','/')\n",
    "print(\"s3 Key - Train: {}\".format(train_s3_key))\n",
    "\n",
    "# Validation\n",
    "val_file = \"lst_files/validation.rec\"\n",
    "val_s3_key = os.path.join(prefix, \"validation\",\"validation.rec\").replace('\\\\','/')\n",
    "print(\"s3 Key - Validation: {}\".format(val_s3_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "#s3_resource.Bucket(bucket).upload_file(Filename=train_file, Key = train_s3_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "#s3_resource.Bucket(bucket).upload_file(Filename=val_file, Key = val_s3_key)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "State Farm Distracted Driver Process Flow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
