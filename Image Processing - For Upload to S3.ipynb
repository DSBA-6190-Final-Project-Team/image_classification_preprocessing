{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to prepare the images in the distracted driver dataset locally, for upload to S3.\n",
    "\n",
    "This notebook will create two versions of the data. The first will be a LST mapping file, with the image files in JPEG format. The second will be a recordio format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: checksumdir in c:\\users\\canfi\\anaconda2\\envs\\dsba_6190_team_proj\\lib\\site-packages (1.1.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install checksumdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z9yTpGbACbX"
   },
   "source": [
    "## Library / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhXJ8brV_4Qb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "\n",
    "import hashlib\n",
    "from checksumdir import dirhash\n",
    "\n",
    "from filecmp import dircmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "406FN849AG3C"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpUao_lNAE88"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/DSBA-6190-Final-Project-Team/DSBA-6190_Final-Project/master/wine_predict/data/driver_imgs_list.csv\"\n",
    "path_file = 'data/driver_imgs_list.csv'\n",
    "\n",
    "df_driver_index = pd.read_csv(path_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr04mwBdAwNY"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1W_1IwhLA7vT",
    "outputId": "6c263b25-d00d-46cc-c0cc-35a5f5e9f47c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 3)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "n3glHqjBA3wI",
    "outputId": "d57b86d9-fe7b-4640-f241-3cba70bfab9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R-sfjF4eAyMI",
    "outputId": "2a8fafe6-343c-4cc7-8b1c-5f64856d2518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'classname', 'img'], dtype='object')"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2w7VZnGBz8G"
   },
   "source": [
    "The following lists each unique driver along with the number of different classname and images are associated with each. Note the number of classnames is not unique, so the images an classnames have equal frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "_vqngHEZBEVL",
    "outputId": "f391960d-5245-42b3-ba56-0cde324c5a5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p002</th>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p012</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p014</th>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p015</th>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p016</th>\n",
       "      <td>1078</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p021</th>\n",
       "      <td>1237</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p022</th>\n",
       "      <td>1233</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p024</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p026</th>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p035</th>\n",
       "      <td>848</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p041</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p042</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p045</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p047</th>\n",
       "      <td>835</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p049</th>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p050</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p051</th>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p052</th>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p056</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p061</th>\n",
       "      <td>809</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p064</th>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p066</th>\n",
       "      <td>1034</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p072</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p075</th>\n",
       "      <td>814</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p081</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         classname   img\n",
       "subject                 \n",
       "p002           725   725\n",
       "p012           823   823\n",
       "p014           876   876\n",
       "p015           875   875\n",
       "p016          1078  1078\n",
       "p021          1237  1237\n",
       "p022          1233  1233\n",
       "p024          1226  1226\n",
       "p026          1196  1196\n",
       "p035           848   848\n",
       "p039           651   651\n",
       "p041           605   605\n",
       "p042           591   591\n",
       "p045           724   724\n",
       "p047           835   835\n",
       "p049          1011  1011\n",
       "p050           790   790\n",
       "p051           920   920\n",
       "p052           740   740\n",
       "p056           794   794\n",
       "p061           809   809\n",
       "p064           820   820\n",
       "p066          1034  1034\n",
       "p072           346   346\n",
       "p075           814   814\n",
       "p081           823   823"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_gb = df_driver_index.groupby(['subject'])\n",
    "drivers_gb.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0KTpe42Cqi6"
   },
   "source": [
    "We will set the training/validation split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNDV8uWICp9y"
   },
   "outputs": [],
   "source": [
    "train_val_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6gBnk_kDXtt"
   },
   "source": [
    "To split the data into training and validation sets, we'll need a unique index of drivers. We don't need the frequency counts.\n",
    "\n",
    "We will create a shuffled list of unique drivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5Lps82L_Dn9-",
    "outputId": "f0aff480-dc8e-471a-d45f-ee9fd2f8d09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042', 'p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_unique = drivers_gb.groups.keys()\n",
    "drivers_unique = list(drivers_unique)\n",
    "\n",
    "random.Random(5590).shuffle(drivers_unique)\n",
    "print(drivers_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOClOK2lEZsD"
   },
   "source": [
    "validation we'll set the list of drivers in the train set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzmgBKnHEfmx"
   },
   "outputs": [],
   "source": [
    "num_drivers_val = round(len(drivers_unique)*train_val_split)\n",
    "#print(num_drivers_val)\n",
    "num_drivers_train = len(drivers_unique) - num_drivers_val\n",
    "#print(num_drivers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "keIIvYaDFeGv",
    "outputId": "a0445d0d-d0e2-4780-a6ab-8ae3abce0bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042']\n"
     ]
    }
   ],
   "source": [
    "drivers_val = drivers_unique[:num_drivers_val]\n",
    "print(drivers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aA1httPIFte_",
    "outputId": "e23ed327-f12f-408b-bf00-8cfeb1d49f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_train = drivers_unique[-num_drivers_train:]\n",
    "print(drivers_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNA4cd_cPquX"
   },
   "source": [
    "# Training and Validation Image Lists\n",
    "We'll now create two lists, one list of every image file name associated with the trainging set, another list associated with the test set. \n",
    "\n",
    "We will use these lists to filter the overall lst mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8a4uhBKP-uQ"
   },
   "outputs": [],
   "source": [
    "df_images_val = df_driver_index[df_driver_index['subject'].isin(drivers_val)]\n",
    "df_images_training = df_driver_index[~df_driver_index['subject'].isin(df_images_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "vHXC2dsXQ2Po",
    "outputId": "d2f863d9-7bdb-493f-d31e-148314e19378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_training.shape)\n",
    "df_images_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "ex0G4NQCRn0j",
    "outputId": "cc7473cf-2acc-41b2-aa75-507a59349d7c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6738, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_27079.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_50749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_97089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_37741.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject classname            img\n",
       "725    p012        c0  img_10206.jpg\n",
       "726    p012        c0  img_27079.jpg\n",
       "727    p012        c0  img_50749.jpg\n",
       "728    p012        c0  img_97089.jpg\n",
       "729    p012        c0  img_37741.jpg"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_val.shape)\n",
    "df_images_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Validation Images\n",
    "We need to move the validation images into a set of validation folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_current = \"D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\"\n",
    "prefix_training = \"imgs\\\\train\"\n",
    "prefix_validation = \"imgs\\\\validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a relative file path to each image. We will create this path for all of the images in the validation set. Then we will move them from the training folders to the validation folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\canfi\\Anaconda2\\envs\\dsba_6190_team_proj\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>rel_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10206.jpg</td>\n",
       "      <td>c0\\img_10206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_27079.jpg</td>\n",
       "      <td>c0\\img_27079.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_50749.jpg</td>\n",
       "      <td>c0\\img_50749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_97089.jpg</td>\n",
       "      <td>c0\\img_97089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_37741.jpg</td>\n",
       "      <td>c0\\img_37741.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_65697.jpg</td>\n",
       "      <td>c0\\img_65697.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_3866.jpg</td>\n",
       "      <td>c0\\img_3866.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_19098.jpg</td>\n",
       "      <td>c0\\img_19098.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_31885.jpg</td>\n",
       "      <td>c0\\img_31885.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_41423.jpg</td>\n",
       "      <td>c0\\img_41423.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject classname            img          rel_path\n",
       "725    p012        c0  img_10206.jpg  c0\\img_10206.jpg\n",
       "726    p012        c0  img_27079.jpg  c0\\img_27079.jpg\n",
       "727    p012        c0  img_50749.jpg  c0\\img_50749.jpg\n",
       "728    p012        c0  img_97089.jpg  c0\\img_97089.jpg\n",
       "729    p012        c0  img_37741.jpg  c0\\img_37741.jpg\n",
       "730    p012        c0  img_65697.jpg  c0\\img_65697.jpg\n",
       "731    p012        c0   img_3866.jpg   c0\\img_3866.jpg\n",
       "732    p012        c0  img_19098.jpg  c0\\img_19098.jpg\n",
       "733    p012        c0  img_31885.jpg  c0\\img_31885.jpg\n",
       "734    p012        c0  img_41423.jpg  c0\\img_41423.jpg"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_val['rel_path'] = df_images_val[['classname', 'img']].apply(lambda x: '\\\\'.join(x), axis = 1) \n",
    "df_images_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\\\\imgs\\\\train'"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path_current, prefix_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor index in df_images_val.index:\\n    path_train = os.path.join(path_current, prefix_training, df_images_val['rel_path'][index])\\n    path_val = os.path.join(path_current, prefix_validation, df_images_val['rel_path'][index])\\n    \\n    #path_train = path_train.replace('\\\\','/')\\n    #path_val = path_val.replace('\\\\','/')\\n    \\n    os.rename(path_train, path_val)\\n\""
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for index in df_images_val.index:\n",
    "    path_train = os.path.join(path_current, prefix_training, df_images_val['rel_path'][index])\n",
    "    path_val = os.path.join(path_current, prefix_validation, df_images_val['rel_path'][index])\n",
    "    \n",
    "    #path_train = path_train.replace('\\\\','/')\n",
    "    #path_val = path_val.replace('\\\\','/')\n",
    "    \n",
    "    os.rename(path_train, path_val)\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now check there are the correct number of files in each directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15686 image files in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "dir_train = os.path.join(path_current, prefix_training)\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_train)])\n",
    "print(\"There are {} image files in the training dataset.\".format(cpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6738 image files in the validation dataset.\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "dir_val = os.path.join(path_current, prefix_validation)\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_val)])\n",
    "print(\"There are {} image files in the validation dataset.\".format(cpt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Flow\n",
    "\n",
    "Some of the downstream processing steps are computationally heavy. Therefore, in order to avoid running these code chunks, without manually commenting them out once run. \n",
    "\n",
    "To check if any of the input files have changed, which would then require reprocessing the images, we will use Hash checksum values to document the state of the inputs. We will check against this state to determine if we need to reprocess the data. \n",
    "\n",
    "To do this, we will have to convert the processing steps into callable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2rec Function Calls\n",
    "The following functions use the im2rec.py tool to process the image inputs.\n",
    "\n",
    "[https://mxnet.apache.org/api/faq/recordio](https://mxnet.apache.org/api/faq/recordio) (Accessed on 3/20/2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LST File Generation\n",
    "These functions perform the first step, creating LST mapping files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_train():\n",
    "    %run tools/im2rec.py lst_files/train imgs/train --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_val():\n",
    "    %run tools/im2rec.py lst_files/validation imgs/validation/ --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recordio Conversion\n",
    "These functions convert the images into a binary recordio binary file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_rec_train():\n",
    "    %run tools/im2rec.py \"lst_files\\train.lst\" \"imgs\\train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_rec_val():\n",
    "    %run tools/im2rec.py \"lst_files\\validation.lst\" \"imgs\\validation\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Hash Checksum\n",
    "The following function generates the Hash of a directory (training or validation images) and writes the Hash in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hash(status):\n",
    "    # Generate File Name, Path and Directory\n",
    "    file_name = \"{}_imgs_hash.csv\".format(status)\n",
    "    file_path = os.path.join(\"hash\", file_name)\n",
    "    file_dir = os.path.join('imgs', status)\n",
    "    \n",
    "    # Generate Hash\n",
    "    dir_hash = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    # Write to CSV\n",
    "    dict_dir_hash = {'hash': [dir_hash]}\n",
    "    df_dir_hash = pd.DataFrame(dict_dir_hash)\n",
    "    df_dir_hash.to_csv(file_path, index=False)\n",
    "    print(\"Hash for {} images successfully written to CSV.\".format(status))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine Processing and Writing Hash\n",
    "Whenever we process the input data we need to write a new hash, and vice versa. Therefore, for simplicity in the final code, we will lump these actions together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_and_write(status):\n",
    "    if status == \"train\":\n",
    "        print(\"Generating LST File: {}\".format(status))\n",
    "        im2rec_lst_train()\n",
    "        print(\"Starting generating REC fil: {}\".format(status))\n",
    "        im2rec_rec_train()\n",
    "        print(\"REC File complete.\")\n",
    "        write_hash(status)\n",
    "    else:\n",
    "        print(\"Generating LST File: {}\".format(status))\n",
    "        im2rec_lst_val()\n",
    "        print(\"Starting generating REC fil: {}\".format(status))\n",
    "        im2rec_rec_val()\n",
    "        print(\"REC File complete.\")\n",
    "        write_hash(status)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow Function\n",
    "The following function will verify the hash of the current files matches the older record. If they match, no action is taken. If they do not match, the input data is processed, and a new hash is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hash(status):\n",
    "    print()\n",
    "    print(\"Status: {}\".format(status))\n",
    "    print()\n",
    "    \n",
    "    # Generate File Name, Path and Directory\n",
    "    file_name = \"{}_imgs_hash.csv\".format(status)\n",
    "    file_path = os.path.join(\"hash\", file_name)\n",
    "    file_dir = os.path.join('imgs', status)\n",
    "    \n",
    "    # Print for Sanity Check\n",
    "    print(\"File Name: {}\".format(file_name))\n",
    "    print(\"File Path: {}\".format(file_path))\n",
    "    print(\"File Directory: {}\".format(file_dir))\n",
    "    print()\n",
    "    \n",
    "    # Generate Current Hash\n",
    "    hash_new = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Hash for {} images do not exist.\".format(status))\n",
    "        print()\n",
    "        im2rec_and_write(status)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        # Read Existing Hash\n",
    "        df_hash_old = pd.read_csv(file_path)\n",
    "        hash_old = df_hash_old.iloc[0]['hash']\n",
    "        \n",
    "        if hash_old == hash_new:\n",
    "            print(\"Hash for {} images are equal.\".format(status))\n",
    "            print(\"New Hash not generated. Processing not required.\")\n",
    "            print()\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            print(\"Hash for {} images are NOT equal.\".format(status))\n",
    "            print()\n",
    "            im2rec_and_write(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Process\n",
    "Runnign the following code chuck will execute the process flow function develpoed above for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Status: train\n",
      "\n",
      "File Name: train_imgs_hash.csv\n",
      "File Path: hash\\train_imgs_hash.csv\n",
      "File Directory: imgs\\train\n",
      "\n",
      "Hash for train images are equal.\n",
      "New Hash not generated. Processing not required.\n",
      "\n",
      "\n",
      "Status: validation\n",
      "\n",
      "File Name: validation_imgs_hash.csv\n",
      "File Path: hash\\validation_imgs_hash.csv\n",
      "File Directory: imgs\\validation\n",
      "\n",
      "Hash for validation images are equal.\n",
      "New Hash not generated. Processing not required.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_list = ['train', 'validation']\n",
    "for status in status_list:\n",
    "    verify_hash(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S3 Upload"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "State Farm Distracted Driver Process Flow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
