{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to prepare the images in the distracted driver dataset locally, for upload to S3.\n",
    "\n",
    "This notebook will create two versions of the data. The first will be a LST mapping file, with the image files in JPEG format. The second will be a recordio format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting checksumdir\n",
      "  Downloading checksumdir-1.1.7.tar.gz (3.1 kB)\n",
      "Building wheels for collected packages: checksumdir\n",
      "  Building wheel for checksumdir (setup.py): started\n",
      "  Building wheel for checksumdir (setup.py): finished with status 'done'\n",
      "  Created wheel for checksumdir: filename=checksumdir-1.1.7-py3-none-any.whl size=4247 sha256=b25353c6ffb3528aad22ffa56f5058aaa5258adc81247bb0fdb6ab820888c28b\n",
      "  Stored in directory: c:\\users\\canfi\\appdata\\local\\pip\\cache\\wheels\\38\\02\\0f\\76662753d74e5b3ddddc1e6daa8fabe369be85f3ca21647b36\n",
      "Successfully built checksumdir\n",
      "Installing collected packages: checksumdir\n",
      "Successfully installed checksumdir-1.1.7\n"
     ]
    }
   ],
   "source": [
    "!pip install checksumdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1z9yTpGbACbX"
   },
   "source": [
    "## Library / Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vhXJ8brV_4Qb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random \n",
    "import os\n",
    "import shutil\n",
    "import boto3\n",
    "\n",
    "import hashlib\n",
    "from checksumdir import dirhash\n",
    "\n",
    "from filecmp import dircmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "406FN849AG3C"
   },
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RpUao_lNAE88"
   },
   "outputs": [],
   "source": [
    "url = \"https://raw.githubusercontent.com/DSBA-6190-Final-Project-Team/DSBA-6190_Final-Project/master/wine_predict/data/driver_imgs_list.csv\"\n",
    "path_file = 'data/driver_imgs_list.csv'\n",
    "\n",
    "df_driver_index = pd.read_csv(path_file) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xr04mwBdAwNY"
   },
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1W_1IwhLA7vT",
    "outputId": "6c263b25-d00d-46cc-c0cc-35a5f5e9f47c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22424, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "n3glHqjBA3wI",
    "outputId": "d57b86d9-fe7b-4640-f241-3cba70bfab9e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "R-sfjF4eAyMI",
    "outputId": "2a8fafe6-343c-4cc7-8b1c-5f64856d2518"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['subject', 'classname', 'img'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_driver_index.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2w7VZnGBz8G"
   },
   "source": [
    "The following lists each unique driver along with the number of different classname and images are associated with each. Note the number of classnames is not unique, so the images an classnames have equal frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 886
    },
    "colab_type": "code",
    "id": "_vqngHEZBEVL",
    "outputId": "f391960d-5245-42b3-ba56-0cde324c5a5b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>p002</th>\n",
       "      <td>725</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p012</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p014</th>\n",
       "      <td>876</td>\n",
       "      <td>876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p015</th>\n",
       "      <td>875</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p016</th>\n",
       "      <td>1078</td>\n",
       "      <td>1078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p021</th>\n",
       "      <td>1237</td>\n",
       "      <td>1237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p022</th>\n",
       "      <td>1233</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p024</th>\n",
       "      <td>1226</td>\n",
       "      <td>1226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p026</th>\n",
       "      <td>1196</td>\n",
       "      <td>1196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p035</th>\n",
       "      <td>848</td>\n",
       "      <td>848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p039</th>\n",
       "      <td>651</td>\n",
       "      <td>651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p041</th>\n",
       "      <td>605</td>\n",
       "      <td>605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p042</th>\n",
       "      <td>591</td>\n",
       "      <td>591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p045</th>\n",
       "      <td>724</td>\n",
       "      <td>724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p047</th>\n",
       "      <td>835</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p049</th>\n",
       "      <td>1011</td>\n",
       "      <td>1011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p050</th>\n",
       "      <td>790</td>\n",
       "      <td>790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p051</th>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p052</th>\n",
       "      <td>740</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p056</th>\n",
       "      <td>794</td>\n",
       "      <td>794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p061</th>\n",
       "      <td>809</td>\n",
       "      <td>809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p064</th>\n",
       "      <td>820</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p066</th>\n",
       "      <td>1034</td>\n",
       "      <td>1034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p072</th>\n",
       "      <td>346</td>\n",
       "      <td>346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p075</th>\n",
       "      <td>814</td>\n",
       "      <td>814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p081</th>\n",
       "      <td>823</td>\n",
       "      <td>823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         classname   img\n",
       "subject                 \n",
       "p002           725   725\n",
       "p012           823   823\n",
       "p014           876   876\n",
       "p015           875   875\n",
       "p016          1078  1078\n",
       "p021          1237  1237\n",
       "p022          1233  1233\n",
       "p024          1226  1226\n",
       "p026          1196  1196\n",
       "p035           848   848\n",
       "p039           651   651\n",
       "p041           605   605\n",
       "p042           591   591\n",
       "p045           724   724\n",
       "p047           835   835\n",
       "p049          1011  1011\n",
       "p050           790   790\n",
       "p051           920   920\n",
       "p052           740   740\n",
       "p056           794   794\n",
       "p061           809   809\n",
       "p064           820   820\n",
       "p066          1034  1034\n",
       "p072           346   346\n",
       "p075           814   814\n",
       "p081           823   823"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drivers_gb = df_driver_index.groupby(['subject'])\n",
    "drivers_gb.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F0KTpe42Cqi6"
   },
   "source": [
    "We will set the training/validation split ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SNDV8uWICp9y"
   },
   "outputs": [],
   "source": [
    "train_val_split = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x6gBnk_kDXtt"
   },
   "source": [
    "To split the data into training and validation sets, we'll need a unique index of drivers. We don't need the frequency counts.\n",
    "\n",
    "We will create a shuffled list of unique drivers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "5Lps82L_Dn9-",
    "outputId": "f0aff480-dc8e-471a-d45f-ee9fd2f8d09e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042', 'p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_unique = drivers_gb.groups.keys()\n",
    "drivers_unique = list(drivers_unique)\n",
    "\n",
    "random.Random(5590).shuffle(drivers_unique)\n",
    "print(drivers_unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YOClOK2lEZsD"
   },
   "source": [
    "validation we'll set the list of drivers in the train set and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rzmgBKnHEfmx"
   },
   "outputs": [],
   "source": [
    "num_drivers_val = round(len(drivers_unique)*train_val_split)\n",
    "#print(num_drivers_val)\n",
    "num_drivers_train = len(drivers_unique) - num_drivers_val\n",
    "#print(num_drivers_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "keIIvYaDFeGv",
    "outputId": "a0445d0d-d0e2-4780-a6ab-8ae3abce0bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p049', 'p022', 'p012', 'p075', 'p045', 'p072', 'p026', 'p042']\n"
     ]
    }
   ],
   "source": [
    "drivers_val = drivers_unique[:num_drivers_val]\n",
    "print(drivers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aA1httPIFte_",
    "outputId": "e23ed327-f12f-408b-bf00-8cfeb1d49f4f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['p015', 'p039', 'p047', 'p081', 'p052', 'p014', 'p021', 'p035', 'p061', 'p064', 'p066', 'p056', 'p002', 'p041', 'p024', 'p016', 'p051', 'p050']\n"
     ]
    }
   ],
   "source": [
    "drivers_train = drivers_unique[-num_drivers_train:]\n",
    "print(drivers_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hNA4cd_cPquX"
   },
   "source": [
    "# Training and Validation Image Lists\n",
    "We'll now create two lists, one list of every image file name associated with the trainging set, another list associated with the test set. \n",
    "\n",
    "We will use these lists to filter the overall lst mapping file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f8a4uhBKP-uQ"
   },
   "outputs": [],
   "source": [
    "df_images_val = df_driver_index[df_driver_index['subject'].isin(drivers_val)]\n",
    "df_images_training = df_driver_index[~df_driver_index['subject'].isin(df_images_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "vHXC2dsXQ2Po",
    "outputId": "d2f863d9-7bdb-493f-d31e-148314e19378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22424, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_44733.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_72999.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_25094.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_69092.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p002</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_92629.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subject classname            img\n",
       "0    p002        c0  img_44733.jpg\n",
       "1    p002        c0  img_72999.jpg\n",
       "2    p002        c0  img_25094.jpg\n",
       "3    p002        c0  img_69092.jpg\n",
       "4    p002        c0  img_92629.jpg"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_training.shape)\n",
    "df_images_training.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "ex0G4NQCRn0j",
    "outputId": "cc7473cf-2acc-41b2-aa75-507a59349d7c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6738, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_27079.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_50749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_97089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_37741.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject classname            img\n",
       "725    p012        c0  img_10206.jpg\n",
       "726    p012        c0  img_27079.jpg\n",
       "727    p012        c0  img_50749.jpg\n",
       "728    p012        c0  img_97089.jpg\n",
       "729    p012        c0  img_37741.jpg"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df_images_val.shape)\n",
    "df_images_val.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Move Validation Images\n",
    "We need to move the validation images into a set of validation folders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_current = \"D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\"\n",
    "prefix_training = \"imgs\\\\train\"\n",
    "prefix_validation = \"imgs\\\\validation\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to create a relative file path to each image. We will create this path for all of the images in the validation set. Then we will move them from the training folders to the validation folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\canfi\\Anaconda2\\envs\\dsba_6190_team_proj\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>classname</th>\n",
       "      <th>img</th>\n",
       "      <th>rel_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_10206.jpg</td>\n",
       "      <td>c0\\img_10206.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_27079.jpg</td>\n",
       "      <td>c0\\img_27079.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_50749.jpg</td>\n",
       "      <td>c0\\img_50749.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_97089.jpg</td>\n",
       "      <td>c0\\img_97089.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_37741.jpg</td>\n",
       "      <td>c0\\img_37741.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_65697.jpg</td>\n",
       "      <td>c0\\img_65697.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_3866.jpg</td>\n",
       "      <td>c0\\img_3866.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_19098.jpg</td>\n",
       "      <td>c0\\img_19098.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_31885.jpg</td>\n",
       "      <td>c0\\img_31885.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>734</th>\n",
       "      <td>p012</td>\n",
       "      <td>c0</td>\n",
       "      <td>img_41423.jpg</td>\n",
       "      <td>c0\\img_41423.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subject classname            img          rel_path\n",
       "725    p012        c0  img_10206.jpg  c0\\img_10206.jpg\n",
       "726    p012        c0  img_27079.jpg  c0\\img_27079.jpg\n",
       "727    p012        c0  img_50749.jpg  c0\\img_50749.jpg\n",
       "728    p012        c0  img_97089.jpg  c0\\img_97089.jpg\n",
       "729    p012        c0  img_37741.jpg  c0\\img_37741.jpg\n",
       "730    p012        c0  img_65697.jpg  c0\\img_65697.jpg\n",
       "731    p012        c0   img_3866.jpg   c0\\img_3866.jpg\n",
       "732    p012        c0  img_19098.jpg  c0\\img_19098.jpg\n",
       "733    p012        c0  img_31885.jpg  c0\\img_31885.jpg\n",
       "734    p012        c0  img_41423.jpg  c0\\img_41423.jpg"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_images_val['rel_path'] = df_images_val[['classname', 'img']].apply(lambda x: '\\\\'.join(x), axis = 1) \n",
    "df_images_val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\\\\imgs\\\\train'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.join(path_current, prefix_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor index in df_images_val.index:\\n    path_train = os.path.join(path_current, prefix_training, df_images_val['rel_path'][index])\\n    path_val = os.path.join(path_current, prefix_validation, df_images_val['rel_path'][index])\\n    \\n    #path_train = path_train.replace('\\\\','/')\\n    #path_val = path_val.replace('\\\\','/')\\n    \\n    os.rename(path_train, path_val)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "for index in df_images_val.index:\n",
    "    path_train = os.path.join(path_current, prefix_training, df_images_val['rel_path'][index])\n",
    "    path_val = os.path.join(path_current, prefix_validation, df_images_val['rel_path'][index])\n",
    "    \n",
    "    #path_train = path_train.replace('\\\\','/')\n",
    "    #path_val = path_val.replace('\\\\','/')\n",
    "    \n",
    "    os.rename(path_train, path_val)\n",
    "''' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now check there are the correct number of files in each directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15686 image files in the training dataset.\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "dir_train = os.path.join(path_current, prefix_training)\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_train)])\n",
    "print(\"There are {} image files in the training dataset.\".format(cpt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 6738 image files in the validation dataset.\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "dir_val = os.path.join(path_current, prefix_validation)\n",
    "\n",
    "cpt = sum([len(files) for r, d, files in os.walk(dir_val)])\n",
    "print(\"There are {} image files in the validation dataset.\".format(cpt))b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Flow\n",
    "\n",
    "Some of the downstream processing steps are computationally heavy. Therefore, in order to avoid running these code chunks, without manually commenting them out once run. \n",
    "\n",
    "To check if any of the input files have changed, which would then require reprocessing the images, we will use Hash checksum values to document the state of the inputs. We will check against this state to determine if we need to reprocess the data. \n",
    "\n",
    "To do this, we will have to convert the processing steps into callable functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## im2rec Function Calls\n",
    "The following functions use the im2rec.py tool to process the image inputs.\n",
    "\n",
    "[https://mxnet.apache.org/api/faq/recordio](https://mxnet.apache.org/api/faq/recordio) (Accessed on 3/20/2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LST File Generation\n",
    "These functions perform the first step, creating LST mapping files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_train():\n",
    "    %run tools/im2rec.py lst_files/train imgs/train --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_val():\n",
    "    %run tools/im2rec.py lst_files/validation imgs/validation/ --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recordio Conversion\n",
    "These functions convert the images into a binary recordio binary file format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_rec_train():\n",
    "    %run tools/im2rec.py \"lst_files\\train.lst\" \"imgs\\train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_rec_val():\n",
    "    %run tools/im2rec.py \"lst_files\\validation.lst\" \"imgs\\validation\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing Hash Checksum\n",
    "The following function generates the Hash of a directory (training or validation images) and writes the Hash in a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_hash(file_name, file_path, file_dir):\n",
    "    # Generate Hash\n",
    "    dir_hash = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    # Write to CSV\n",
    "    dict_dir_hash = {'hash': [dir_hash]}\n",
    "    df_dir_hash = pd.DataFrame(dict_dir_hash)\n",
    "    df_dir_hash.to_csv(file_path, index=False)\n",
    "    print(\"Hash for {} images successfully written to CSV.\".format(status))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Flow Function\n",
    "The following function will verify the hash of the current files matches the older record. If they match, no action is taken. If they do not match, the input data is processed, and a new hash is generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_hash(status):\n",
    "    print()\n",
    "    print(\"Status: {}\".format(status))\n",
    "    print()\n",
    "    \n",
    "    # Generate File Name, Path and Directory\n",
    "    file_name = \"{}_imgs_hash.csv\".format(status)\n",
    "    file_path = os.path.join(\"hash\", file_name)\n",
    "    file_dir = os.path.join('imgs', status)\n",
    "    \n",
    "    # Print for Sanity Check\n",
    "    print(\"File Name: {}\".format(file_name))\n",
    "    print(\"File Path: {}\".format(file_path))\n",
    "    print(\"File Directory: {}\".format(file_dir))\n",
    "    print()\n",
    "    \n",
    "    # Generate Current Hash\n",
    "    hash_new = dirhash(file_dir, 'sha256')\n",
    "    \n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Hash for {} images do not exist.\".format(status))\n",
    "        print()\n",
    "        # Generate LST\n",
    "        # Generate REC\n",
    "        write_hash(file_name, file_path, file_dir)\n",
    "        return\n",
    "    \n",
    "    else:\n",
    "        # Read Existing Hash\n",
    "        df_hash_old = pd.read_csv(file_path)\n",
    "        hash_old = df_hash_old.iloc[0]['hash']\n",
    "        \n",
    "        if hash_old == hash_new:\n",
    "            print(\"Hash for {} images are equal.\".format(status))\n",
    "            print(\"New Hash not generated. Processing not required.\")\n",
    "            print()\n",
    "            return\n",
    "        \n",
    "        else:\n",
    "            print(\"Hash for {} images are NOT equal.\".format(status))\n",
    "            print()\n",
    "            # Generate LST\n",
    "            # Generate REC\n",
    "            write_hash(file_name, file_path, file_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Process\n",
    "Runnign the following code chuck will execute the process flow function develpoed above for both training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: train\n",
      "\n",
      "File Name: train_imgs_hash.csv\n",
      "File Path: hash\\train_imgs_hash.csv\n",
      "File Directory: imgs\\train\n",
      "\n",
      "Hash for train images are equal.\n",
      "New Hash not generated.\n",
      "\n",
      "Status: validation\n",
      "\n",
      "File Name: validation_imgs_hash.csv\n",
      "File Path: hash\\validation_imgs_hash.csv\n",
      "File Directory: imgs\\validation\n",
      "\n",
      "Hash for validation images are equal.\n",
      "New Hash not generated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "status_list = ['train', 'validation']\n",
    "for status in status_list:\n",
    "    verify_hash(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LST Files\n",
    "\n",
    "The Sagemaker Image Classification Algorithm requires either an LST or REC file as input, one for the training and one for the validation set. The file acts as a mapping function, connecting the image of each set to the image file location and the image class.\n",
    "\n",
    "Now that the files have be sorted into training and validation sets, we will create the training and validation LST files.\n",
    "\n",
    "The lst tool is im2rec.py, found here: [https://mxnet.apache.org/api/faq/recordio](https://mxnet.apache.org/api/faq/recordio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lst_files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-155-47f14ef4901d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_lst_loc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlst_files\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtrain_imgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'imgs/train'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'lst_files' is not defined"
     ]
    }
   ],
   "source": [
    "train_lst_loc = 'lst_files/train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_train():\n",
    "    %run tools/im2rec.py lst_files/train imgs/train --list --recursive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2rec_lst_val():\n",
    "    %run tools/im2rec.py lst_files/validation imgs/validation/ --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 0\n",
      "c1 1\n",
      "c2 2\n",
      "c3 3\n",
      "c4 4\n",
      "c5 5\n",
      "c6 6\n",
      "c7 7\n",
      "c8 8\n",
      "c9 9\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: 'D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\\\\**train_lst_loc.lst'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32mD:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\tools\\im2rec.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    327\u001b[0m     \u001b[1;31m# if the '--list' is used, it generates .lst file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mmake_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m     \u001b[1;31m# otherwise read .lst file to generates .rec file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\tools\\im2rec.py\u001b[0m in \u001b[0;36mmake_list\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[0msep_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk_size\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_ratio\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 115\u001b[1;33m             \u001b[0mwrite_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr_chunk\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.lst'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    116\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_ratio\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\tools\\im2rec.py\u001b[0m in \u001b[0;36mwrite_list\u001b[1;34m(path_out, image_list)\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[0mimage_list\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mline\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'%d\\t'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: 'D:\\\\Notebooks\\\\dsba_6190\\\\team_project\\\\image_classification_preprocessing\\\\**train_lst_loc.lst'"
     ]
    }
   ],
   "source": [
    "%run tools/im2rec.py **train_lst_loc imgs/train --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c0 0\n",
      "c1 1\n",
      "c2 2\n",
      "c3 3\n",
      "c4 4\n",
      "c5 5\n",
      "c6 6\n",
      "c7 7\n",
      "c8 8\n",
      "c9 9\n"
     ]
    }
   ],
   "source": [
    "%run tools/im2rec.py lst_files/validation imgs/validation/ --list --recursive "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REC Binary File Creation\n",
    "\n",
    "We will now transform the images from standard image formats to recordio format, for better processing in the image classification algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from D:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\lst_files\\train.lst in D:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\lst_files\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.053854942321777344  count: 0\n",
      "time: 36.72012400627136  count: 1000\n",
      "time: 40.099653482437134  count: 2000\n",
      "time: 33.50782084465027  count: 3000\n",
      "time: 29.593960523605347  count: 4000\n",
      "time: 30.440842151641846  count: 5000\n",
      "time: 28.752363204956055  count: 6000\n",
      "time: 31.05421471595764  count: 7000\n",
      "time: 31.182876586914062  count: 8000\n",
      "time: 40.862788677215576  count: 9000\n",
      "time: 29.686290740966797  count: 10000\n",
      "time: 28.63100504875183  count: 11000\n",
      "time: 29.594340562820435  count: 12000\n",
      "time: 28.277966499328613  count: 13000\n",
      "time: 35.239041805267334  count: 14000\n",
      "time: 39.334925413131714  count: 15000\n"
     ]
    }
   ],
   "source": [
    "#%run tools/im2rec.py \"lst_files\\train.lst\" \"imgs\\train\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating .rec file from D:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\lst_files\\validation.lst in D:\\Notebooks\\dsba_6190\\team_project\\image_classification_preprocessing\\lst_files\n",
      "multiprocessing not available, fall back to single threaded encoding\n",
      "time: 0.06337356567382812  count: 0\n",
      "time: 28.41474437713623  count: 1000\n",
      "time: 27.819944381713867  count: 2000\n",
      "time: 36.39020895957947  count: 3000\n",
      "time: 40.80285167694092  count: 4000\n",
      "time: 51.46012330055237  count: 5000\n",
      "time: 33.11307072639465  count: 6000\n"
     ]
    }
   ],
   "source": [
    "#%run tools/im2rec.py \"lst_files\\validation.lst\" \"imgs\\validation\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89017af1cfb0525ebb81e27d42a30df2f2359ba0efd1a92350b544b2baac4a63\n"
     ]
    }
   ],
   "source": [
    "with open(\"lst_files/train.idx\", \"rb\") as f:\n",
    "\n",
    "    print(hashlib.sha256(f.read()).hexdigest())"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "State Farm Distracted Driver Process Flow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
